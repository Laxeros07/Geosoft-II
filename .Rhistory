4+5
a04+5
4=4+5
a=4+5
a
b
b=1+2
b
a=5/(5+34)
?sin
b=2*sin(90)
c=sqrt(16)+sqrt(25)
d=(a+b)/c
?seq
?rep
rep.int(1, 5)
load("students.rdata")
load("students.rdata")
load("C:/Users/Felix/Desktop/Studium/Uni Fächer/2. Semester/Geostatistik/R-Dateien/Datensätze/students.rdata")
data(iris) # lade den Datensatz
iris[40:60,] # Zeige Zeilen 40 bis 60
?mean
mean(Sepal.Length)
mean(iris.Sepal.Length)
mean(iris[,1])
iris
i=iris[40:60,]
mean(i[,1])
sd(i[,1])
?sd
median(i[,1])
?quantile
quantile(i[,1],0.1)
quantile(i[,1],0.5)
quantile(i[,1],0.1)
quantile(i[,1],0.9)
?sort
sort(iris$Sepal.Length[40:60])[11]
ls()
str(students)
table(students$EyeColor)
table(students$Gender)
table(students$Age)
table(students$Length)
table(students$Iam)
table(students$Country)
table(students$FieldOfStudies)
table(students$Semester)
h=hist(students$Length, plot=FALSE)
h
5+27
hist(students$Length)
?sum
med <- median(students$Length, na.rm = TRUE)
students$ali <- ((students$Semester / 2) / students$Age) * 100
quartiles.students$ali
quantile(students$ali, fracs, na.rm = TRUE)
quantile(students$ali, na.rm = TRUE)
?str
?which
str(students$ali)
str(students$ali.which(10))
str(students$ali.which(>=10))
str(students$ali.which(x>=10))
str(which(students$ali>=10))
students$ali
str(which(students$ali>=10))/str(which(students$ali>=0))
which(students$ali>=10)/which(students$ali>=0)
9/133
students.m <- students[students$Gender == "m", ]
plot(x = students.m$Age, y = students.m$Semester)
mean(students.m$Semester, na.rm = TRUE)
median(students.m$Semester, na.rm = TRUE)
students.m.clean <- students.m[students.m$Semester < 10, ]
median(students.m.clean$Semester, na.rm = TRUE)
mean(students.m.clean$Semester, na.rm = TRUE)
mean(students.m$Semester, trim = 0.1, na.rm = TRUE)
mean(students.m$Semester, trim = 0.3, na.rm = TRUE)
mean(students.m$Semester, trim = 0.5, na.rm = TRUE)
median(students.m$Semester, na.rm = TRUE)
?mean
?quartil
?quartil
?quartiles
?quartile
?quatile
?quantile
quantile(students$Length, fracs,na.rm = TRUE)
quantile(students$Length,na.rm = TRUE)
fracs = c(0.25)
fracs = c(0.75)
quantile(students$Length, fracs, na.rm = TRUE)
fracz = c(0.75)
quantile(students$Length, fracz, na.rm = TRUE) -quantile(students$Length, fracs, na.rm = TRUE)
fracs = c(0.25)
fracz = c(0.75)
quantile(students$Length, fracz, na.rm = TRUE) - quantile(students$Length, fracs, na.rm = TRUE)
quantile(students$Length, fracz, na.rm = TRUE)
quantile(students$Length, fracs, na.rm = TRUE)
?na.omit
h=hist(students$Length, plot=FALSE)
h
hist(students$Length)
h= 170 < hist(students$Length, plot=FALSE) < 180
?which
sum(which(170<hist(students$Length, plot=FALSE)<180))
sum(which(hist(students$Length, plot=FALSE)<180))
sum(hist(students$Length, plot=FALSE)<180)
students$Length
sum(which(students$Length<180))
sum(which(170<students$Length<180))
sum(which(students$Length<180&&<170))
sum(which(students$Length<180&&>170))
(which(students$Length<180))
(which(students$Length<180 && >170))
(which(170<students$Length<180))
sum(students$Length<180)
sum(170<students$Length<180)
sum(students$Length<180&&students$Length>170)
sum(students$Length<180&&>170)
students$Length
hist(students$Length, plot=FALSE)
sum(students$Length=180)
sum(students$Length=170)
sum(students$Length==170)
sum(students$Length==180)
> hist(students$Length, plot=FALSE)
hist(students$Length, plot=FALSE)
sum(students$Length==170)
sum(students$Length==180)
hist(students$Length)
50-3-9
sum(students$Length==150)
sum(students$Length==170)
5+27-3
sum(students$Length<=180)
quantile(students$ali, na.rm = TRUE)
quantile(stdents$ali, c(0.25))
quantile(students$ali, c(0.25))
quantile(students$ali, c(0.25),na.rm = TRUE)
which(students$ali>=10)/which(students$ali>=0)
which(students$ali>=10)
which(students$ali>=0)
9/133
plot(x = students.m$Age, y = students.m$Semester)
mean(students.m$Semester, na.rm = TRUE)
median(students.m$Semester, na.rm = TRUE)
students.m.clean <- students.m[students.m$Semester < 10, ]
mean(students.m.clean$Semester, na.rm = TRUE)
median(students.m.clean$Semester, na.rm = TRUE)
load("ex01_AABU.rdata")
load("ex01_AABU.Rdata")
load("ex01_AABU.Rdata")
load("ex01_AABU.Rdata")
summary(AABU.obs)
class(maske_raster)
maske_raster <- c(7.55738996178022, 7.64064656833175, 51.9372943715445, 52.0001517816852)
class(maske_raster)
ext(maske_raster)
maske_raster <- c(xmin =7.55738996178022, xmax =7.64064656833175, ymin =51.9372943715445, ymax =52.0001517816852)
ext(maske_raster)
rasterdaten <- crop(rasterdaten, ext(maske_raster))
## librarys installieren
library(terra)
library(sf)
library(caret)
library(raster)
library(CAST)
library(cowplot)
library(tidyterra)
library(RColorBrewer)
maske_raster <- c(xmin =7.55738996178022, xmax =7.64064656833175, ymin =51.9372943715445, ymax =52.0001517816852)
ext(maske_raster)
maske_raster <- c(7.55738996178022, 7.64064656833175, 51.9372943715445, 52.0001517816852)
ext(maske_raster)
plot(ext(maske_raster))
plot(ext(maske_training))
maske_training <- c(xmin =7.55738996178022, ymin =51.9372943715445, xmax =7.64064656833175, ymax =52.0001517816852)
plot(ext(maske_training))
class(maske_raster)
class(maske_raster) <- "character"
class(maske_raster)
class(maske_raster) <- "numeric"
class(maske_raster)
sf_use_s2(FALSE)
trainingsdaten2 <- st_make_valid(trainingsdaten)
trainingsdaten <- read_sf(paste(
getwd(),
"/public/uploads/trainingsdaten.geojson",
sep = ""
))
# zum testen wd so setzen
setwd("C:/Users/Felix/Desktop/Studium/Uni Fächer/4. Semester/Geosoft 1/Geosoft-II")
trainingsdaten <- read_sf(paste(
getwd(),
"/public/uploads/trainingsdaten.geojson",
sep = ""
))
class(maske_raster)
trainingsdaten2 <- st_make_valid(trainingsdaten)
trainingsdaten <- st_crop(trainingsdaten2, maske_training)
## librarys installieren
library(terra)
library(sf)
library(caret)
library(raster)
library(CAST)
library(cowplot)
library(tidyterra)
library(RColorBrewer)
# zum testen wd so setzen
setwd("C:/Users/Felix/Desktop/Studium/Uni Fächer/4. Semester/Geosoft 1/Geosoft-II")
rasterdaten <- rast(paste(
getwd(),
"/public/uploads/rasterdaten.tif",
sep = ""
))
trainingsdaten <- read_sf(paste(
getwd(),
"/public/uploads/trainingsdaten.geojson",
sep = ""
))
modell <- readRDS(paste(
getwd(),
"/public/uploads/modell.RDS",
sep = ""
))
maske_raster <- c(7.55738996178022, 7.64064656833175, 51.9372943715445, 52.0001517816852)
maske_training <- c(xmin =7.55738996178022, ymin =51.9372943715445, xmax =7.64064656833175, ymax =52.0001517816852)
## Variablen definieren
predictors <- c(
"B02", "B03", "B04", "B08", "B05", "B06", "B07", "B11",
"B12", "B8A"
)
# Trainingsdaten umprojizieren, falls die Daten verschiedene CRS haben
trainingsdaten <- st_transform(trainingsdaten, crs(rasterdaten))
# Daten mergen
extr <<- extract(rasterdaten, trainingsdaten)
# head(extr)
# head(trainingsdaten)
trainingsdaten$PolyID <- 1:nrow(trainingsdaten)
extr <<- merge(extr, trainingsdaten, by.x = "ID", by.y = "PolyID")
# Modell trainieren
# nicht alle Daten verwenden um Rechenzeit zu sparen
extr_subset <- extr[createDataPartition(extr$ID, p = 0.2)$Resample1, ]
# eventuell Daten limitieren.
# Verhälnis der Daten aus jedem Trainingsgebiet soll aber gleich bleiben
# hier:10% aus jedem Trainingsgebiet (see ?createDataPartition)
trainIDs <- createDataPartition(extr$ID, p = 0.1, list = FALSE)
trainDat <- extr[trainIDs, ]
# Sicherstellen das kein NA in Prädiktoren enthalten ist:
trainDat <- trainDat[complete.cases(trainDat[, predictors]), ]
#### Modelltraining
model <- train(trainDat[, predictors],
trainDat$Label,
method = "rf",
importance = TRUE,
ntree = 50
) # 50 is quite small (default=500). But it runs faster.
# Farbpalette
cols <- c(
"beige", "sandybrown",
"blue3", "red", "magenta", "red", "darkgoldenrod", "lightgreen", "blue", "green", "deeppink4", "grey", "chartreuse", "deeppink3",
"deepskyblue4", "forestgreen", "brown", "darkgreen"
)
# klassifizieren
### little detour due to terra/raster change
prediction <- predict(as(rasterdaten, "Raster"), model)#, colors(cols))
projection(prediction)<- "+proj=longlat +datum=WGS84 +no_defs +type=crs"
prediction_terra <- as(prediction, "SpatRaster")
coltab(prediction_terra) <- brewer.pal(n = 10, name = "RdBu")
# Prediction Legende exportieren
legend_plot <- ggplot()+
geom_spatraster(data=prediction_terra)+
scale_fill_manual(values=brewer.pal(n = 10, name = "RdBu"), na.value=NA)
legend <- get_legend(legend_plot)
plot(legend)
ggsave(paste(
getwd(),
"/public/uploads/legend.png",
sep = ""
), plot= legend)
?ggsave
ggsave(paste(
getwd(),
"/public/uploads/legend.png",
sep = ""
), plot= legend, width = 2, height = 3)
?train
#### Modelltraining
model <- train(trainDat[, predictors],
trainDat$Label,
method = "rf",
importance = TRUE,
ntree = 50,
maxnodes = NULL,
) # 50 is quite small (default=500). But it runs faster.
maxnodes
maxnodes <-
if(is.null(baumAnzahl)){
baumAnzahl == 50
}
baumAnzahl <- 40
baumTiefe <- 5
if(is.null(baumAnzahl)){
baumAnzahl == 50
}
#### Modelltraining
model <- train(trainDat[, predictors],
trainDat$Label,
method = "rf",
importance = TRUE,
ntree = baumAnzahl,  # Anzahl der Bäume
maxnodes = baumTiefe,   # Tiefe der Bäume
) # 50 is quite small (default=500). But it runs faster.
model
baumTiefe <- 20
#### Modelltraining
model <- train(trainDat[, predictors],
trainDat$Label,
method = "rf",
importance = TRUE,
ntree = baumAnzahl,  # Anzahl der Bäume
maxnodes = baumTiefe,   # Tiefe der Bäume
) # 50 is quite small (default=500). But it runs faster.
model
baumTiefe <- 50
#### Modelltraining
model <- train(trainDat[, predictors],
trainDat$Label,
method = "rf",
importance = TRUE,
ntree = baumAnzahl,  # Anzahl der Bäume
maxnodes = baumTiefe,   # Tiefe der Bäume
) # 50 is quite small (default=500). But it runs faster.
model
baumTiefe <- 100
#### Modelltraining
model <- train(trainDat[, predictors],
trainDat$Label,
method = "rf",
importance = TRUE,
ntree = baumAnzahl,  # Anzahl der Bäume
maxnodes = baumTiefe,   # Tiefe der Bäume
) # 50 is quite small (default=500). But it runs faster.
model
#### Modelltraining
model <- train(trainDat[, predictors],
trainDat$Label,
method = "rf",
importance = TRUE,
ntree = baumAnzahl,  # Anzahl der Bäume
maxnodes = baumTiefe   # Tiefe der Bäume
) # 50 is quite small (default=500). But it runs faster.
model
